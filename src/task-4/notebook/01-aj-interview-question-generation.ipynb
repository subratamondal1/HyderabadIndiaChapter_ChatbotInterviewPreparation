{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Interview Question Generation\n",
    "`Author: Abdlazeez Jimoh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAgent:\n",
    "    def __init__(self):\n",
    "        self.client = OpenAI()\n",
    "        self.system_prompt = None\n",
    "        self.user_prompt = None\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def run(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class QuestionGeneratorAgentV1(BaseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.system_prompt = \"\"\"You are a non-technical interviewer that generate at least 4 interview questions across the following categories:\n",
    "- personal\n",
    "- role-specific\n",
    "- behavioural\n",
    "- situational\n",
    "\n",
    "Make sure there is a question for each category.\n",
    "\n",
    "You answer strictly as single JSON string. Don't include any other verbose texts and don't include the markdown syntax anywhere.\n",
    "\n",
    "JSON format:\n",
    "[\n",
    "    {\"question\": \"<question>\", \"question_type\": \"<question_type>\"}\n",
    "]\"\"\"\n",
    "        self.user_prompt = \"{description}\"\n",
    "\n",
    "    def __call__(self, description: str, n_questions: int = 5) -> list[dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Generate interview questions based on the given description.\n",
    "\n",
    "        Args:\n",
    "            description (str): The description used as input for question generation.\n",
    "            n_questions (int, optional): The number of questions to generate. Defaults to 5.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of generated interview questions.\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate questions\n",
    "        questions = self._generate(description, n_questions)\n",
    "\n",
    "        return questions\n",
    "\n",
    "    def run(self, description: str, n_questions: int = 5) -> list[dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Generate interview questions based on the given description.\n",
    "\n",
    "        Args:\n",
    "            description (str): The description used as input for question generation.\n",
    "            n_questions (int, optional): The number of questions to generate. Defaults to 5.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of generated interview questions.\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate questions\n",
    "        questions = self._generate(description, n_questions)\n",
    "\n",
    "        return questions\n",
    "\n",
    "    def _generate(self, description: str, n_questions: int) -> list[dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Generate interview questions based on the given description.\n",
    "\n",
    "        Args:\n",
    "            description (str): The description used as input for question generation.\n",
    "            n_questions (int): The number of questions to generate.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of generated interview questions.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            output = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo-1106\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": self.system_prompt,\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": self.user_prompt.format(description=description),\n",
    "                    },\n",
    "                ],\n",
    "                temperature=0.5,\n",
    "                max_tokens=1024,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0,\n",
    "            )\n",
    "\n",
    "            questions = json.loads(output.choices[0].message.content or \"[]\")\n",
    "\n",
    "            return questions\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return []\n",
    "\n",
    "\n",
    "class QuestionGeneratorAgentV2(BaseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.system_prompt = \"\"\"You are a non-technical interviewer that interviews across the following categories:\n",
    "- personal\n",
    "- role-specific\n",
    "- behavioural\n",
    "- situational\n",
    "\n",
    "Your questions should be based on the provided candidate's description.\n",
    "\n",
    "Generate {n_questions} questions, ensuring that there is a question for each category.\n",
    "\n",
    "* You answer strictly as a list of JSON objects. Don't include any other verbose texts, and don't include the markdown syntax anywhere.\n",
    "\n",
    "JSON format:\n",
    "[\n",
    "    {{\"question\": \"<personal_question>\", \"question_type\": \"personal\"}},\n",
    "    {{\"question\": \"<role_specific_question>\", \"question_type\": \"role-specific\"}},\n",
    "    {{\"question\": \"<behavioural_question>\", \"question_type\": \"behavioural\"}},\n",
    "    {{\"question\": \"<situational_question>\", \"question_type\": \"situational\"}},\n",
    "    ...\n",
    "]\"\"\"\n",
    "\n",
    "        self.user_prompt = \"{description}\"\n",
    "\n",
    "    def __call__(self, description: str, n_questions: int = 4) -> list[dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Generate interview questions based on the given description.\n",
    "\n",
    "        Args:\n",
    "            description (str): The description used as input for question generation.\n",
    "            n_questions (int, optional): The number of questions to generate. Defaults to 4.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of generated interview questions.\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate questions\n",
    "        questions = self._generate(description, n_questions)\n",
    "\n",
    "        return questions\n",
    "\n",
    "    def run(self, description: str, n_questions: int = 4) -> list[dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Generate interview questions based on the given description.\n",
    "\n",
    "        Args:\n",
    "            description (str): The description used as input for question generation.\n",
    "            n_questions (int, optional): The number of questions to generate. Defaults to 4.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of generated interview questions.\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate questions\n",
    "        questions = self._generate(description, n_questions)\n",
    "\n",
    "        return questions\n",
    "\n",
    "    def _generate(self, description: str, n_questions: int) -> list[dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Generate interview questions based on the given description.\n",
    "\n",
    "        Args:\n",
    "            description (str): The description used as input for question generation.\n",
    "            n_questions (int): The number of questions to generate.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of generated interview questions.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            # Ensure that there are at least 4 questions\n",
    "            if n_questions < 4:\n",
    "                n_questions = 4\n",
    "\n",
    "            output = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo-1106\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": self.system_prompt.format(n_questions=n_questions),\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": self.user_prompt.format(description=description),\n",
    "                    },\n",
    "                ],\n",
    "                temperature=0.5,\n",
    "                max_tokens=1024,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0,\n",
    "            )\n",
    "            questions = json.loads(output.choices[0].message.content or \"[]\")\n",
    "\n",
    "            return questions\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'question': 'Tell me about a time when you had to quickly learn a new '\n",
      "              'technology or programming language. How did you approach the '\n",
      "              'challenge?',\n",
      "  'question_type': 'behavioural'},\n",
      " {'question': 'Can you walk me through a recent project you worked on and the '\n",
      "              'role you played in its development?',\n",
      "  'question_type': 'role-specific'},\n",
      " {'question': 'How do you prioritize your tasks and manage your time '\n",
      "              'effectively, especially in a fast-paced startup environment?',\n",
      "  'question_type': 'situational'},\n",
      " {'question': 'What do you consider to be your greatest technical strength, '\n",
      "              'and how does it contribute to your effectiveness as a software '\n",
      "              'engineer?',\n",
      "  'question_type': 'personal'},\n",
      " {'question': 'Imagine you have to work on a project with a tight deadline and '\n",
      "              'limited resources. How would you approach this situation to '\n",
      "              'ensure successful delivery?',\n",
      "  'question_type': 'situational'}]\n"
     ]
    }
   ],
   "source": [
    "question_generator = QuestionGeneratorAgentV1()\n",
    "questions = question_generator.run(\n",
    "    \"a software engineer at a startup in San Francisco. I have 5 years of experience and I'm looking for a new job.\"\n",
    ")\n",
    "\n",
    "pprint(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'question': 'What inspired you to pursue a career in software engineering?',\n",
      "  'question_type': 'personal'},\n",
      " {'question': 'Can you discuss a project where you had to work with limited '\n",
      "              'resources and tight deadlines?',\n",
      "  'question_type': 'role-specific'},\n",
      " {'question': 'Tell me about a time when you had to adapt to a significant '\n",
      "              'change in a project. How did you handle it?',\n",
      "  'question_type': 'behavioural'},\n",
      " {'question': \"You're working on a project with a tight deadline and one of \"\n",
      "              'your team members falls ill. How would you handle this '\n",
      "              'situation?',\n",
      "  'question_type': 'situational'}]\n"
     ]
    }
   ],
   "source": [
    "question_generator2 = QuestionGeneratorAgentV2()\n",
    "questions2 = question_generator2.run(\n",
    "    \"a software engineer at a startup in San Francisco. I have 5 years of experience and I'm looking for a new job.\",\n",
    ")\n",
    "\n",
    "pprint(questions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'question': 'What inspired you to pursue a career in data science?',\n",
      "  'question_type': 'personal'},\n",
      " {'question': 'Can you explain how you implemented the recommendation engine '\n",
      "              'for the e-commerce company?',\n",
      "  'question_type': 'role-specific'},\n",
      " {'question': 'Tell me about a time when you had to resolve a conflict within '\n",
      "              'your team while working on a project.',\n",
      "  'question_type': 'behavioural'},\n",
      " {'question': 'How would you approach a situation where the data for a project '\n",
      "              'is incomplete or unreliable?',\n",
      "  'question_type': 'situational'}]\n"
     ]
    }
   ],
   "source": [
    "question_generator2 = QuestionGeneratorAgentV2()\n",
    "questions3 = question_generator2.run(\n",
    "    \"a data scientist from India. I have 3 years of experience. I've worked on a variety of projects, including a recommendation engine for a large e-commerce company. I've led a team of 5 data scientists and engineers.\",\n",
    ")\n",
    "\n",
    "pprint(questions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
